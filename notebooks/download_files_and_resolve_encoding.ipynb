{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f0dc264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing year 2020 ---\n",
      "Downloading 2020.csv.zip...\n",
      "File downloaded and saved to: ..\\data\\sus\\2020.csv.zip\n",
      "Extracting 2020.csv.zip...\n",
      "Deleting 2020.csv.zip...\n",
      "Converting encoding for 2020.csv...\n",
      "Error processing 2020: Error tokenizing data. C error: Expected 6 fields in line 28, saw 7\n",
      "\n",
      "\n",
      "--- Processing year 2021 ---\n",
      "Downloading 2021.csv.zip...\n",
      "File downloaded and saved to: ..\\data\\sus\\2021.csv.zip\n",
      "Extracting 2021.csv.zip...\n",
      "Deleting 2021.csv.zip...\n",
      "Converting encoding for 2021.csv...\n",
      "Error processing 2021: Error tokenizing data. C error: Expected 4 fields in line 17, saw 5\n",
      "\n",
      "\n",
      "--- Processing year 2022 ---\n",
      "Downloading 2022.csv.zip...\n",
      "File downloaded and saved to: ..\\data\\sus\\2022.csv.zip\n",
      "Extracting 2022.csv.zip...\n",
      "Deleting 2022.csv.zip...\n",
      "Converting encoding for 2022.csv...\n",
      "Error processing 2022: Error tokenizing data. C error: Expected 3 fields in line 4, saw 9\n",
      "\n",
      "\n",
      "--- Processing year 2023 ---\n",
      "Downloading 2023.csv.zip...\n",
      "File downloaded and saved to: ..\\data\\sus\\2023.csv.zip\n",
      "Extracting 2023.csv.zip...\n",
      "Deleting 2023.csv.zip...\n",
      "Converting encoding for 2023.csv...\n",
      "Error processing 2023: Error tokenizing data. C error: Expected 8 fields in line 6, saw 9\n",
      "\n",
      "\n",
      "--- Processing year 2024 ---\n",
      "Downloading 2024.csv.zip...\n",
      "File downloaded and saved to: ..\\data\\sus\\2024.csv.zip\n",
      "Extracting 2024.csv.zip...\n",
      "Deleting 2024.csv.zip...\n",
      "Converting encoding for 2024.csv...\n",
      "Error processing 2024: Error tokenizing data. C error: Expected 7 fields in line 6, saw 9\n",
      "\n",
      "\n",
      "All downloads completed!\n",
      "\n",
      "Contents of ..\\data\\sus:\n",
      "  2020.csv\n",
      "  2021.csv\n",
      "  2022.csv\n",
      "  2023.csv\n",
      "  2024.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "data_dir = Path(\"../data/sus\")\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Base URL pattern\n",
    "base_url = \"https://s3.sa-east-1.amazonaws.com/ckan.saude.gov.br/BPS/csv/{year}.csv.zip\"\n",
    "\n",
    "# Years to download\n",
    "years = range(2020, 2025)  # 2020 to 2024 inclusive\n",
    "\n",
    "for year in years:\n",
    "    print(f\"\\n--- Processing year {year} ---\")\n",
    "    \n",
    "    # URL for the current year\n",
    "    url = base_url.format(year=year)\n",
    "    \n",
    "    try:\n",
    "        # Download the file\n",
    "        print(f\"Downloading {year}.csv.zip...\")\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Raise an exception for bad status codes\n",
    "        \n",
    "        # Save the zip file\n",
    "        zip_path = data_dir / f\"{year}.csv.zip\"\n",
    "        with open(zip_path, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        \n",
    "        print(f\"File downloaded and saved to: {zip_path}\")\n",
    "        \n",
    "        # Extract the zip file\n",
    "        print(f\"Extracting {year}.csv.zip...\")\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(data_dir)\n",
    "        \n",
    "        # Delete the zip file after extraction\n",
    "        print(f\"Deleting {year}.csv.zip...\")\n",
    "        zip_path.unlink()\n",
    "        \n",
    "        # Find the extracted CSV file and fix encoding\n",
    "        csv_file = data_dir / f\"{year}.csv\"\n",
    "        if csv_file.exists():\n",
    "            print(f\"Converting encoding for {year}.csv...\")\n",
    "            # Try different encodings to handle accents properly\n",
    "            for encoding in ['utf-8', 'latin-1', 'iso-8859-1', 'cp1252']:\n",
    "                try:\n",
    "                    df = pd.read_csv(csv_file, encoding=encoding)\n",
    "                    # Save as UTF-8 to preserve accents\n",
    "                    df.to_csv(csv_file, encoding='utf-8', index=False)\n",
    "                    print(f\"Successfully converted {year}.csv with {encoding} encoding!\")\n",
    "                    break\n",
    "                except UnicodeDecodeError:\n",
    "                    continue\n",
    "            else:\n",
    "                print(f\"Warning: Could not determine encoding for {year}.csv\")\n",
    "        \n",
    "        print(f\"Processing completed for {year}!\")\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error downloading {year}: {e}\")\n",
    "    except zipfile.BadZipFile as e:\n",
    "        print(f\"Error extracting {year}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {year}: {e}\")\n",
    "\n",
    "print(f\"\\nAll downloads completed!\")\n",
    "\n",
    "# List the contents of the directory to verify\n",
    "print(f\"\\nContents of {data_dir}:\")\n",
    "for item in sorted(data_dir.iterdir()):\n",
    "    print(f\"  {item.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8538a439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding detectado pelo chardet: {'encoding': 'ISO-8859-1', 'confidence': 0.73, 'language': ''}\n",
      "❌ Erro com utf-8: 'utf-8' codec can't decode byte 0xe7 in position 13: invalid continuation byte\n",
      "\n",
      "--- Testando encoding: latin-1 ---\n",
      "✓ Separador correto (;) e encoding funcionando\n",
      "Colunas encontradas: ['Nome Instituição', 'CNPJ Instituição', 'Município Instituição']\n",
      "Amostra da primeira linha:\n",
      "  Nome Instituição: FUNDO MUNICIPAL DE SAUDE\n",
      "  Município: MURICI\n",
      "\n",
      "--- Informações do arquivo ---\n",
      "Tamanho: 7.62 MB\n",
      "\n",
      "--- Primeiras linhas do arquivo (raw) ---\n",
      "b'Nome Institui\\xe7\\xe3o;CNPJ Institui\\xe7\\xe3o;Munic\\xedpio Institui\\xe7\\xe3o;UF;Compra;Inser\\xe7\\xe3o;Modalidade da Compra;C\\xf3digo BR;Descri\\xe7\\xe3o CATMAT;Unidade Fornecimento;Gen\\xe9rico;ANVISA;CNPJ Fornecedor;Fornecedor;CNPJ Fabricante;Fabricante;Qtd Itens Comprados;Pre\\xe7o Unit\\xe1rio;Pre\\xe7o Total\\r\\nFUNDO MUNICIPAL DE SAUDE;11.120.699/0001-40;MURICI;AL;45292;45513;Preg\\xe3o;365246;EXTRATO, TIPO:EXTRATO GLIC\\xd3LICO, NOME COMUM:BABOSA, NOME BOT\\xc2NICO:ALOE VERA L., ASPECTO F\\xcdSICO:L\\xcdQUIDO;LITRO;N;;00.236.193/0001-84;CIRURGICA RECIFE COMERCIO E'\n"
     ]
    }
   ],
   "source": [
    "# Vamos analisar e corrigir o problema de encoding\n",
    "import chardet\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Primeiro, definir o data_dir novamente após o restart do kernel\n",
    "data_dir = Path(\"../data/sus\")\n",
    "\n",
    "# Verificar o encoding detectado do arquivo 2024.csv\n",
    "csv_path = data_dir / \"2024.csv\"\n",
    "\n",
    "if csv_path.exists():\n",
    "    # Detectar encoding do arquivo\n",
    "    with open(csv_path, 'rb') as f:\n",
    "        raw_data = f.read(50000)  # Ler primeiros 50KB para melhor detecção\n",
    "        detected = chardet.detect(raw_data)\n",
    "        print(f\"Encoding detectado pelo chardet: {detected}\")\n",
    "    \n",
    "    # Tentar ler com diferentes encodings e mostrar uma amostra\n",
    "    encodings_to_try = ['utf-8', 'latin-1', 'iso-8859-1', 'cp1252', 'windows-1252', 'cp850']\n",
    "    \n",
    "    for encoding in encodings_to_try:\n",
    "        try:\n",
    "            df_sample = pd.read_csv(csv_path, encoding=encoding, nrows=2, sep=';')\n",
    "            print(f\"\\n--- Testando encoding: {encoding} ---\")\n",
    "            # Verificar se temos a coluna correta\n",
    "            if 'Nome Instituição' in df_sample.columns:\n",
    "                print(\"✓ Separador correto (;) e encoding funcionando\")\n",
    "                print(\"Colunas encontradas:\", df_sample.columns.tolist()[:3])\n",
    "                print(\"Amostra da primeira linha:\")\n",
    "                print(f\"  Nome Instituição: {df_sample.iloc[0]['Nome Instituição']}\")\n",
    "                print(f\"  Município: {df_sample.iloc[0]['Município Instituição'] if 'Município Instituição' in df_sample.columns else 'N/A'}\")\n",
    "                break\n",
    "            else:\n",
    "                print(f\"❌ Colunas encontradas: {df_sample.columns.tolist()[:3]}\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Erro com {encoding}: {str(e)[:100]}\")\n",
    "    \n",
    "    print(f\"\\n--- Informações do arquivo ---\")\n",
    "    print(f\"Tamanho: {csv_path.stat().st_size / (1024*1024):.2f} MB\")\n",
    "    \n",
    "    # Verificar as primeiras linhas do arquivo raw\n",
    "    print(f\"\\n--- Primeiras linhas do arquivo (raw) ---\")\n",
    "    with open(csv_path, 'rb') as f:\n",
    "        first_lines = f.read(500)\n",
    "        print(repr(first_lines))\n",
    "        \n",
    "else:\n",
    "    print(\"Arquivo 2024.csv não encontrado\")\n",
    "    print(\"Arquivos disponíveis:\")\n",
    "    if data_dir.exists():\n",
    "        for item in data_dir.iterdir():\n",
    "            print(f\"  {item.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a449ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DOWNLOAD E CONVERSÃO CORRIGIDA ===\n",
      "\n",
      "--- Processando ano 2020 ---\n",
      "Arquivo 2020.csv já existe. Verificando encoding...\n",
      "Arquivo 2020.csv existe mas precisa ser corrigido...\n",
      "Baixando 2020.csv.zip...\n",
      "  Arquivo baixado: ..\\data\\sus\\2020.csv.zip\n",
      "Extraindo 2020.csv.zip...\n",
      "  Arquivo zip removido\n",
      "Processando encoding de 2020.csv...\n",
      "  Encoding detectado: MacRoman (confiança: 0.73)\n",
      "❌ Não foi possível processar 2020.csv corretamente\n",
      "✓ Processamento concluído para 2020!\n",
      "\n",
      "--- Processando ano 2021 ---\n",
      "Arquivo 2021.csv já existe. Verificando encoding...\n",
      "Arquivo 2021.csv existe mas precisa ser corrigido...\n",
      "Baixando 2021.csv.zip...\n",
      "  Arquivo baixado: ..\\data\\sus\\2021.csv.zip\n",
      "Extraindo 2021.csv.zip...\n",
      "  Arquivo zip removido\n",
      "Processando encoding de 2021.csv...\n",
      "  Encoding detectado: ISO-8859-1 (confiança: 0.73)\n",
      "❌ Não foi possível processar 2021.csv corretamente\n",
      "✓ Processamento concluído para 2021!\n",
      "\n",
      "--- Processando ano 2022 ---\n",
      "Arquivo 2022.csv já existe. Verificando encoding...\n",
      "Arquivo 2022.csv existe mas precisa ser corrigido...\n",
      "Baixando 2022.csv.zip...\n",
      "  Arquivo baixado: ..\\data\\sus\\2022.csv.zip\n",
      "Extraindo 2022.csv.zip...\n",
      "  Arquivo zip removido\n",
      "Processando encoding de 2022.csv...\n",
      "  Encoding detectado: ISO-8859-1 (confiança: 0.73)\n",
      "❌ Não foi possível processar 2022.csv corretamente\n",
      "✓ Processamento concluído para 2022!\n",
      "\n",
      "--- Processando ano 2023 ---\n",
      "Arquivo 2023.csv já existe. Verificando encoding...\n",
      "Arquivo 2023.csv existe mas precisa ser corrigido...\n",
      "Baixando 2023.csv.zip...\n",
      "  Arquivo baixado: ..\\data\\sus\\2023.csv.zip\n",
      "Extraindo 2023.csv.zip...\n",
      "  Arquivo zip removido\n",
      "Processando encoding de 2023.csv...\n",
      "  Encoding detectado: ISO-8859-1 (confiança: 0.73)\n",
      "  ✓ Sucesso com encoding: ISO-8859-1\n",
      "  ✓ Arquivo convertido para UTF-8\n",
      "✓ 2023.csv processado com sucesso usando ISO-8859-1\n",
      "✓ Processamento concluído para 2023!\n",
      "\n",
      "--- Processando ano 2024 ---\n",
      "Arquivo 2024.csv já existe. Verificando encoding...\n",
      "Arquivo 2024.csv existe mas precisa ser corrigido...\n",
      "Baixando 2024.csv.zip...\n",
      "  Arquivo baixado: ..\\data\\sus\\2024.csv.zip\n",
      "Extraindo 2024.csv.zip...\n",
      "  Arquivo zip removido\n",
      "Processando encoding de 2024.csv...\n",
      "  Encoding detectado: ISO-8859-1 (confiança: 0.73)\n",
      "  ✓ Sucesso com encoding: ISO-8859-1\n",
      "  ✓ Arquivo convertido para UTF-8\n",
      "✓ 2024.csv processado com sucesso usando ISO-8859-1\n",
      "✓ Processamento concluído para 2024!\n",
      "\n",
      "=== DOWNLOAD CONCLUÍDO ===\n",
      "\n",
      "Arquivos no diretório:\n",
      "  2020.csv (41.30 MB)\n",
      "  2021.csv (41.11 MB)\n",
      "  2022.csv (40.03 MB)\n",
      "  2023.csv (12.33 MB)\n",
      "  2024.csv (7.79 MB)\n"
     ]
    }
   ],
   "source": [
    "# VERSÃO CORRIGIDA: Download e processamento com encoding adequado\n",
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import chardet\n",
    "\n",
    "def detect_and_convert_encoding(file_path):\n",
    "    \"\"\"\n",
    "    Detecta o encoding do arquivo e converte para UTF-8 se necessário\n",
    "    \"\"\"\n",
    "    # Detectar encoding\n",
    "    with open(file_path, 'rb') as f:\n",
    "        raw_data = f.read(100000)  # Ler 100KB para boa detecção\n",
    "        detected = chardet.detect(raw_data)\n",
    "        detected_encoding = detected['encoding']\n",
    "        confidence = detected['confidence']\n",
    "    \n",
    "    print(f\"  Encoding detectado: {detected_encoding} (confiança: {confidence:.2f})\")\n",
    "    \n",
    "    # Lista de encodings para tentar, priorizando o detectado\n",
    "    encodings_to_try = [detected_encoding, 'latin-1', 'cp1252', 'iso-8859-1', 'windows-1252']\n",
    "    \n",
    "    # Remover None e duplicatas, mantendo ordem\n",
    "    encodings_to_try = list(dict.fromkeys([enc for enc in encodings_to_try if enc]))\n",
    "    \n",
    "    for encoding in encodings_to_try:\n",
    "        try:\n",
    "            # Tentar ler o arquivo\n",
    "            df = pd.read_csv(file_path, encoding=encoding, sep=';')\n",
    "            \n",
    "            # Verificar se o arquivo foi lido corretamente\n",
    "            if len(df.columns) > 10 and 'Nome Instituição' in df.columns:\n",
    "                print(f\"  ✓ Sucesso com encoding: {encoding}\")\n",
    "                \n",
    "                # Salvar como UTF-8\n",
    "                df.to_csv(file_path, encoding='utf-8', sep=';', index=False)\n",
    "                print(f\"  ✓ Arquivo convertido para UTF-8\")\n",
    "                \n",
    "                return True, encoding\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  ❌ Falha com {encoding}: {str(e)[:50]}...\")\n",
    "            continue\n",
    "    \n",
    "    return False, None\n",
    "\n",
    "# Recriar diretório se necessário\n",
    "data_dir = Path(\"../data/sus\")\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Base URL pattern\n",
    "base_url = \"https://s3.sa-east-1.amazonaws.com/ckan.saude.gov.br/BPS/csv/{year}.csv.zip\"\n",
    "\n",
    "# Anos para download\n",
    "years = range(2020, 2025)  # 2020 to 2024 inclusive\n",
    "\n",
    "print(\"=== DOWNLOAD E CONVERSÃO CORRIGIDA ===\\n\")\n",
    "\n",
    "for year in years:\n",
    "    print(f\"--- Processando ano {year} ---\")\n",
    "    \n",
    "    # URL para o ano atual\n",
    "    url = base_url.format(year=year)\n",
    "    \n",
    "    try:\n",
    "        # Verificar se já existe e está ok\n",
    "        csv_file = data_dir / f\"{year}.csv\"\n",
    "        if csv_file.exists():\n",
    "            print(f\"Arquivo {year}.csv já existe. Verificando encoding...\")\n",
    "            \n",
    "            # Tentar ler uma amostra para verificar se está ok\n",
    "            try:\n",
    "                test_df = pd.read_csv(csv_file, encoding='utf-8', sep=';', nrows=5)\n",
    "                if 'Nome Instituição' in test_df.columns and len(test_df.columns) > 10:\n",
    "                    print(f\"✓ Arquivo {year}.csv já está correto!\")\n",
    "                    continue\n",
    "            except:\n",
    "                print(f\"Arquivo {year}.csv existe mas precisa ser corrigido...\")\n",
    "        \n",
    "        # Download do arquivo\n",
    "        print(f\"Baixando {year}.csv.zip...\")\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Salvar o arquivo zip\n",
    "        zip_path = data_dir / f\"{year}.csv.zip\"\n",
    "        with open(zip_path, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        \n",
    "        print(f\"  Arquivo baixado: {zip_path}\")\n",
    "        \n",
    "        # Extrair o arquivo zip\n",
    "        print(f\"Extraindo {year}.csv.zip...\")\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(data_dir)\n",
    "        \n",
    "        # Deletar o arquivo zip\n",
    "        zip_path.unlink()\n",
    "        print(f\"  Arquivo zip removido\")\n",
    "        \n",
    "        # Processar encoding do CSV extraído\n",
    "        if csv_file.exists():\n",
    "            print(f\"Processando encoding de {year}.csv...\")\n",
    "            success, used_encoding = detect_and_convert_encoding(csv_file)\n",
    "            \n",
    "            if success:\n",
    "                print(f\"✓ {year}.csv processado com sucesso usando {used_encoding}\")\n",
    "            else:\n",
    "                print(f\"❌ Não foi possível processar {year}.csv corretamente\")\n",
    "        \n",
    "        print(f\"✓ Processamento concluído para {year}!\\n\")\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"❌ Erro no download de {year}: {e}\")\n",
    "    except zipfile.BadZipFile as e:\n",
    "        print(f\"❌ Erro na extração de {year}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erro no processamento de {year}: {e}\")\n",
    "\n",
    "print(\"=== DOWNLOAD CONCLUÍDO ===\\n\")\n",
    "\n",
    "# Verificar conteúdo do diretório\n",
    "print(\"Arquivos no diretório:\")\n",
    "for item in sorted(data_dir.iterdir()):\n",
    "    if item.is_file():\n",
    "        size_mb = item.stat().st_size / (1024*1024)\n",
    "        print(f\"  {item.name} ({size_mb:.2f} MB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc2f8771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TESTE DE LEITURA COM ACENTOS ===\n",
      "\n",
      "Arquivo carregado com sucesso!\n",
      "Dimensões: (24635, 19)\n",
      "Colunas: 19\n",
      "\n",
      "--- Teste de acentos ---\n",
      "Primeiras 3 colunas:\n",
      "  Nome Instituição\n",
      "  CNPJ Instituição\n",
      "  Município Instituição\n",
      "\n",
      "Primeiras 5 linhas da coluna 'Nome Instituição':\n",
      "  1. FUNDO MUNICIPAL DE SAUDE\n",
      "  2. FUNDO MUNICIPAL DE SAUDE\n",
      "  3. FUNDO MUNICIPAL DE SAUDE\n",
      "  4. FUNDO MUNICIPAL DE SAUDE\n",
      "  5. FUNDO MUNICIPAL DE SAUDE\n",
      "\n",
      "Primeiras 5 linhas da coluna 'Município Instituição':\n",
      "  1. MURICI\n",
      "  2. MURICI\n",
      "  3. MURICI\n",
      "  4. MURICI\n",
      "  5. MURICI\n",
      "\n",
      "Primeiras 5 linhas da coluna 'Descrição CATMAT':\n",
      "  1. EXTRATO, TIPO:EXTRATO GLICÓLICO, NOME COMUM:BABOSA, NOME BOTÂNICO:ALOE VERA L., ASPECTO FÍSICO:LÍQUI...\n",
      "  2. OLANZAPINA, DOSAGEM:5 MG...\n",
      "  3. VALPROATO DE SÓDIO, CONCENTRAÇÃO:500 MG...\n",
      "  4. NORETISTERONA, CONCENTRAÇAO:0,35 MG, CARACTERÍSTICAS ADICIONAIS:EM BLISTER CALENDÁRIO...\n",
      "  5. EQUIPO ESPECIAL, APLICAÇÃO:P/ INJEÇÃO GÁS CARBÔNICO CO2 - VIA SC, NÚMERO VIAS:VIA ÚNICA, MATERIAL:TU...\n",
      "\n",
      "--- Verificação de acentos ---\n",
      "Acentos em 'Nome Instituição': ❌ NÃO\n",
      "Acentos em 'Município Instituição': ❌ NÃO\n",
      "\n",
      "⚠️  Os acentos ainda não estão sendo detectados adequadamente.\n"
     ]
    }
   ],
   "source": [
    "# TESTE FINAL: Verificar se os acentos estão sendo lidos corretamente\n",
    "print(\"=== TESTE DE LEITURA COM ACENTOS ===\\n\")\n",
    "\n",
    "# Testar leitura do arquivo 2024.csv\n",
    "csv_path = data_dir / \"2024.csv\"\n",
    "\n",
    "if csv_path.exists():\n",
    "    try:\n",
    "        # Ler com UTF-8\n",
    "        df = pd.read_csv(csv_path, encoding='utf-8', sep=';')\n",
    "        \n",
    "        print(f\"Arquivo carregado com sucesso!\")\n",
    "        print(f\"Dimensões: {df.shape}\")\n",
    "        print(f\"Colunas: {len(df.columns)}\")\n",
    "        \n",
    "        print(f\"\\n--- Teste de acentos ---\")\n",
    "        print(\"Primeiras 3 colunas:\")\n",
    "        for col in df.columns[:3]:\n",
    "            print(f\"  {col}\")\n",
    "        \n",
    "        print(f\"\\nPrimeiras 5 linhas da coluna 'Nome Instituição':\")\n",
    "        for i, nome in enumerate(df['Nome Instituição'].head()):\n",
    "            print(f\"  {i+1}. {nome}\")\n",
    "        \n",
    "        print(f\"\\nPrimeiras 5 linhas da coluna 'Município Instituição':\")\n",
    "        for i, municipio in enumerate(df['Município Instituição'].head()):\n",
    "            print(f\"  {i+1}. {municipio}\")\n",
    "            \n",
    "        print(f\"\\nPrimeiras 5 linhas da coluna 'Descrição CATMAT':\")\n",
    "        for i, desc in enumerate(df['Descrição CATMAT'].head()):\n",
    "            print(f\"  {i+1}. {desc[:100]}...\")  # Mostrar apenas os primeiros 100 caracteres\n",
    "        \n",
    "        # Verificar se temos acentos\n",
    "        nome_com_acento = df['Nome Instituição'].str.contains('ção|ção|ão|ões|ções|ê|á|é|í|ó|ú|â|ã|õ|ç', na=False).any()\n",
    "        municipio_com_acento = df['Município Instituição'].str.contains('ção|ção|ão|ões|ções|ê|á|é|í|ó|ú|â|ã|õ|ç', na=False).any()\n",
    "        \n",
    "        print(f\"\\n--- Verificação de acentos ---\")\n",
    "        print(f\"Acentos em 'Nome Instituição': {'✓ SIM' if nome_com_acento else '❌ NÃO'}\")\n",
    "        print(f\"Acentos em 'Município Instituição': {'✓ SIM' if municipio_com_acento else '❌ NÃO'}\")\n",
    "        \n",
    "        if nome_com_acento or municipio_com_acento:\n",
    "            print(\"\\n🎉 SUCESSO! Os acentos estão sendo lidos corretamente!\")\n",
    "        else:\n",
    "            print(\"\\n⚠️  Os acentos ainda não estão sendo detectados adequadamente.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erro ao ler o arquivo: {e}\")\n",
    "else:\n",
    "    print(\"❌ Arquivo 2024.csv não encontrado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4eeba862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FUNÇÕES CRIADAS ===\n",
      "✓ carregar_dados_sus(ano, sample_size=None)\n",
      "✓ resumo_dados_sus(ano)\n",
      "\n",
      "Exemplo de uso:\n",
      "  df_2024 = carregar_dados_sus(2024)\n",
      "  resumo_dados_sus(2024)\n",
      "✓ Dados de 2024 carregados: 1,000 registros, 19 colunas\n",
      "\n",
      "=== RESUMO DOS DADOS DE 2024 ===\n",
      "Colunas disponíveis:\n",
      "   1. Nome Instituição\n",
      "   2. CNPJ Instituição\n",
      "   3. Município Instituição\n",
      "   4. UF\n",
      "   5. Compra\n",
      "   6. Inserção\n",
      "   7. Modalidade da Compra\n",
      "   8. Código BR\n",
      "   9. Descrição CATMAT\n",
      "  10. Unidade Fornecimento\n",
      "  11. Genérico\n",
      "  12. ANVISA\n",
      "  13. CNPJ Fornecedor\n",
      "  14. Fornecedor\n",
      "  15. CNPJ Fabricante\n",
      "  16. Fabricante\n",
      "  17. Qtd Itens Comprados\n",
      "  18. Preço Unitário\n",
      "  19. Preço Total\n",
      "\n",
      "Estatísticas básicas:\n",
      "  • Instituições únicas: 5\n",
      "  • Municípios únicos: 5\n",
      "  • UFs únicas: 5\n",
      "  • Fornecedores únicos: 12\n",
      "  • Valor total (amostra): R$ 17,749,162.65\n",
      "  • Valor médio por item: R$ 17,749.16\n"
     ]
    }
   ],
   "source": [
    "# FUNÇÃO UTILITÁRIA: Carregar dados de qualquer ano\n",
    "def carregar_dados_sus(ano, sample_size=None):\n",
    "    \"\"\"\n",
    "    Carrega dados do SUS para um ano específico\n",
    "    \n",
    "    Args:\n",
    "        ano (int): Ano dos dados (2020-2024)\n",
    "        sample_size (int, optional): Número de linhas para carregar (None = todas)\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame: Dados carregados\n",
    "    \"\"\"\n",
    "    csv_path = data_dir / f\"{ano}.csv\"\n",
    "    \n",
    "    if not csv_path.exists():\n",
    "        raise FileNotFoundError(f\"Arquivo {ano}.csv não encontrado. Execute o download primeiro.\")\n",
    "    \n",
    "    try:\n",
    "        if sample_size:\n",
    "            df = pd.read_csv(csv_path, encoding='utf-8', sep=';', nrows=sample_size)\n",
    "        else:\n",
    "            df = pd.read_csv(csv_path, encoding='utf-8', sep=';')\n",
    "        \n",
    "        print(f\"✓ Dados de {ano} carregados: {df.shape[0]:,} registros, {df.shape[1]} colunas\")\n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Erro ao carregar dados de {ano}: {e}\")\n",
    "\n",
    "def resumo_dados_sus(ano):\n",
    "    \"\"\"\n",
    "    Mostra um resumo dos dados do SUS para um ano\n",
    "    \"\"\"\n",
    "    df = carregar_dados_sus(ano, sample_size=1000)  # Carregar amostra para resumo\n",
    "    \n",
    "    print(f\"\\n=== RESUMO DOS DADOS DE {ano} ===\")\n",
    "    print(f\"Colunas disponíveis:\")\n",
    "    for i, col in enumerate(df.columns, 1):\n",
    "        print(f\"  {i:2d}. {col}\")\n",
    "    \n",
    "    print(f\"\\nEstatísticas básicas:\")\n",
    "    print(f\"  • Instituições únicas: {df['Nome Instituição'].nunique():,}\")\n",
    "    print(f\"  • Municípios únicos: {df['Município Instituição'].nunique():,}\")\n",
    "    print(f\"  • UFs únicas: {df['UF'].nunique()}\")\n",
    "    print(f\"  • Fornecedores únicos: {df['Fornecedor'].nunique():,}\")\n",
    "    \n",
    "    # Converter preço total para numérico para estatísticas\n",
    "    df['Preço Total'] = pd.to_numeric(df['Preço Total'].astype(str).str.replace(',', '.'), errors='coerce')\n",
    "    \n",
    "    print(f\"  • Valor total (amostra): R$ {df['Preço Total'].sum():,.2f}\")\n",
    "    print(f\"  • Valor médio por item: R$ {df['Preço Total'].mean():,.2f}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Exemplo de uso\n",
    "print(\"=== FUNÇÕES CRIADAS ===\")\n",
    "print(\"✓ carregar_dados_sus(ano, sample_size=None)\")\n",
    "print(\"✓ resumo_dados_sus(ano)\")\n",
    "print(\"\\nExemplo de uso:\")\n",
    "print(\"  df_2024 = carregar_dados_sus(2024)\")\n",
    "print(\"  resumo_dados_sus(2024)\")\n",
    "\n",
    "# Testar com dados de 2024\n",
    "try:\n",
    "    resumo_2024 = resumo_dados_sus(2024)\n",
    "except Exception as e:\n",
    "    print(f\"Erro no teste: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
